{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rolling window functions: Calculating heatwaves\n",
    "\n",
    "Let's use Xarray to calculate heatwave statistics over 150 years, for every gridpoint in the CMIP5 ACCESS 1.3 historical run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import xarray\n",
    "import dask\n",
    "import numpy\n",
    "from scipy.stats import norm\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by loading the full tasmax dataset from the NCI archive. The files will be automatically joined, and it will use the dask library to only load the data that it needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = xarray.open_mfdataset('/g/data/rr3/publications/CMIP5/output1/CSIRO-BOM/ACCESS1-3/historical/day/atmos/day/r1i1p1/latest/tasmax/tasmax_day_ACCESS1-3_historical_r1i1p1_*.nc')\n",
    "tasmax = d.tasmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the 90th percentile temperature for each day of the year\n",
    "\n",
    "Heatwaves are defined as a period of at least three days where for each day the temperature is in the top 10% for that day of the year - [scorcher.org.au](http://scorcher.org.au/about#measure)\n",
    "\n",
    "First we'll calculate the climatology - the 90th percentile temperature at each grid point for each day in the year. \n",
    "\n",
    "We could use numpy's percentile function to calculate this, but it would be slow. Numpy calculates percentiles by sorting the array and finding the value 90% along the sorted list. Sorting is a terrible operation to perform on a large dataset - it's slow to do and you need the entire array in memory, which is exactly what we're trying to avoid.\n",
    "\n",
    "Instead let's assume the temperatures are normally distributed, and estimate the 90th percentile from the mean and standard deviation, each of which are fast to calculate. A more thourough investigation would check this assumption.\n",
    "\n",
    "Calling `.groupby()` on a DataArray lets you use the split-apply-combine strategy on the data\n",
    " - Split the data into multiple groups, based on the coordinates\n",
    " - Apply a function on each group\n",
    " - Combine the groups back into a single dataset\n",
    "\n",
    "You can group a time axis in particular in many different ways - year, month, day, dayofweek, dayofyear, quarter, season.\n",
    "\n",
    "There are a number of pre-defined operators you can use as the apply function - `.min()`, `.mean()`, `.std()` etc., or you can define your own.\n",
    "\n",
    "[`scipy.stats.norm.ppf()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html) can be used to get the percentile of a normal distribution, given the mean and standard deviation\n",
    "\n",
    "[Xarray docs: datetime components](http://xarray.pydata.org/en/stable/time-series.html#datetime-components)  \n",
    "[Xarray docs: split-apply-combine](http://xarray.pydata.org/en/stable/groupby.html)  \n",
    "[Xarray docs: GroupBy objects](http://xarray.pydata.org/en/stable/generated/xarray.core.groupby.DataArrayGroupBy.html)\n",
    "\n",
    "<div class=\"accordion\" id=\"accordion\">\n",
    "  <div class=\"card\">\n",
    "    <div class=\"card-header\" id=\"headingOne\">\n",
    "      <h5 class=\"mb-0\">\n",
    "        <button class=\"btn btn-link\" type=\"button\" data-toggle=\"collapse\" data-target=\"#collapse1\">\n",
    "          Answer\n",
    "        </button>\n",
    "      </h5>\n",
    "    </div>\n",
    "  <div>\n",
    "    <div id=\"collapse1\" class=\"collapse\" data-parent=\"#accordion\">\n",
    "      <div class=\"card-body\">\n",
    "<pre><code>\n",
    "# Get the mean and standard deviation for each grid point and day of year\n",
    "mean = tasmax.groupby('time.dayofyear').mean('time')\n",
    "std = tasmax.groupby('time.dayofyear').std('time')\n",
    "\n",
    "# Get the 90th percentile for each grid point and day of year, assuming normal distributions\n",
    "p90 = xarray.DataArray(norm.ppf(0.9, loc=mean, scale=std), coords=mean.coords)\n",
    "</code></pre>\n",
    "      </div>\n",
    "    </div>\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find candidate points\n",
    "\n",
    "With the climatology we can find the locations where the maximum temperature exceeds the 90th percentile for that day of the year. \n",
    "\n",
    "Use [`.where()`](http://xarray.pydata.org/en/stable/generated/xarray.DataArray.where.html) to filter the temperature field, so that it only contains grid points where the temperature exceeds the 90th percentile calculated above\n",
    "\n",
    "For best results here you should use a recent version of dask (after June 2018), as comparing against a climatology was dramatically improved.\n",
    "\n",
    "[Xarray docs: `.where()`](http://xarray.pydata.org/en/stable/generated/xarray.DataArray.where.html)\n",
    "\n",
    "<div class=\"accordion\" id=\"accordion\">\n",
    "  <div class=\"card\">\n",
    "    <div class=\"card-header\" id=\"headingOne\">\n",
    "      <h5 class=\"mb-0\">\n",
    "        <button class=\"btn btn-link\" type=\"button\" data-toggle=\"collapse\" data-target=\"#collapse2\">\n",
    "          Answer\n",
    "        </button>\n",
    "      </h5>\n",
    "    </div>\n",
    "  <div>\n",
    "    <div id=\"collapse2\" class=\"collapse\" data-parent=\"#accordion\">\n",
    "      <div class=\"card-body\">\n",
    "<pre><code>\n",
    "candidates = tasmax.where((tasmax.groupby('time.dayofyear') - p90) > 0)\n",
    "</code></pre>\n",
    "      </div>\n",
    "    </div>\n",
    "  </div>\n",
    "</div>\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a timeseries plot for a single location\n",
    "\n",
    "Now for a bit of signal processing. We have an array of candidate times and locations, but it's only a heatwave for a location if there are at least three consecutive times.\n",
    "\n",
    "We want to calculate the number of heatwaves at each location. The easiest way to think about this is to narrow down our data while we get a handle on our data.\n",
    "\n",
    "Create a plot of the temperature at a single location for a single year, and overlay the candidate points onto the plot\n",
    "\n",
    "Here's some locations to try:\n",
    "\n",
    "Sydney: lat -33.9 lon 151.2,\n",
    "Melbourne: lat -37.8 lon 145.0,\n",
    "Canberra: lat -35.3 lon 149.1,\n",
    "Hobart: lat -42.9 lon 147.3\n",
    "\n",
    "[Xarray docs: Nearest neighbour lookups](http://xarray.pydata.org/en/stable/indexing.html#nearest-neighbor-lookups)\n",
    "\n",
    "<div class=\"accordion\" id=\"accordion\">\n",
    "  <div class=\"card\">\n",
    "    <div class=\"card-header\" id=\"headingOne\">\n",
    "      <h5 class=\"mb-0\">\n",
    "        <button class=\"btn btn-link\" type=\"button\" data-toggle=\"collapse\" data-target=\"#collapse3\">\n",
    "          Answer\n",
    "        </button>\n",
    "      </h5>\n",
    "    </div>\n",
    "  <div>\n",
    "    <div id=\"collapse3\" class=\"collapse\" data-parent=\"#accordion\">\n",
    "      <div class=\"card-body\">\n",
    "<pre><code>\n",
    "tasmax.sel(lat=-37.8, lon=144.9, method='nearest').sel(time='1998').plot(alpha=0.5)\n",
    "candidates.sel(lat=-37.8, lon=144.9, method='nearest').sel(time='1998').plot(color='red')\n",
    "</code></pre>\n",
    "      </div>\n",
    "    </div>\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify heatwaves with a basic window function\n",
    "\n",
    "To help with processing time series Xarray has rolling window functions, which can help with things like temporal smoothing. We'll use this feature to find times where there are three consecutive candidate points - these will be our heatwaves.\n",
    "\n",
    "You can set up a window function collecting 3 samples in the time dimension using `.rolling(time=3)`. Just like `.groupby()` there are a number of reduction calculations you can use on the window.\n",
    "\n",
    "Use `.rolling()` and a reduction function to mark heatwaves on the plot you created in the previous step.\n",
    "\n",
    "[Xarray docs: `.rolling()`](http://xarray.pydata.org/en/stable/generated/xarray.DataArray.rolling.html#xarray.DataArray.rolling)  \n",
    "[Xarray docs: Rolling objects](http://xarray.pydata.org/en/stable/generated/xarray.core.rolling.DataArrayRolling.html#xarray.core.rolling.DataArrayRolling)\n",
    "\n",
    "<div class=\"accordion\" id=\"accordion\">\n",
    "  <div class=\"card\">\n",
    "    <div class=\"card-header\" id=\"headingOne\">\n",
    "      <h5 class=\"mb-0\">\n",
    "        <button class=\"btn btn-link\" type=\"button\" data-toggle=\"collapse\" data-target=\"#collapse4\">\n",
    "          Answer\n",
    "        </button>\n",
    "      </h5>\n",
    "    </div>\n",
    "  <div>\n",
    "    <div id=\"collapse4\" class=\"collapse\" data-parent=\"#accordion\">\n",
    "      <div class=\"card-body\">\n",
    "<pre><code>\n",
    "tasmax.sel(lat=-37.8, lon=144.9, method='nearest').sel(time='1998').plot(alpha=0.5)\n",
    "candidates.sel(lat=-37.8, lon=144.9, method='nearest').sel(time='1998').plot(color='red')\n",
    "\n",
    "# To plot this on the same axis I'm filtering the candidates with .where() to show times when a heatwave was found\n",
    "candidates.where(\n",
    "    candidates.rolling(time=3).count()==3\n",
    ").sel(lat=-37.8, lon=144.9, method='nearest').sel(time='1998').plot(marker='.')\n",
    "</code></pre>\n",
    "      </div>\n",
    "    </div>\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zoom in on some events\n",
    "\n",
    "Did you find any heatwaves? Zoom in on a few to see how well our filter worked (It may help to add markers with `.plot(marker='.')`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More advanced filters\n",
    "\n",
    "As a first pass this works but it is a bit crude - it correctly identifies heatwaves, but doesn't allow us to count them. To do that, I need to define a custom filter function to apply to the window.\n",
    "\n",
    "To count the heatwaves I need to be a bit more specific than I have been, since each instance occurs over a number of time points. Let's say I want to count the *starts* of the heatwaves - where it transitions from not a candidate to a candidate for 3 steps, so I want to match the pattern\n",
    "```\n",
    "[ nan, valid, valid, valid ]\n",
    "```\n",
    "with the second point being marked as the date the heatwave starts. To do this I've created the filter function below. So that the times get marked correctly the function is intended to be used with a centred window function - it returns true if the entry one to the left is `nan` and that the current entry plus the two to the right are finite values, false otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rising_filter(array, axis):\n",
    "    \"\"\"\n",
    "    Returns locations when the values of array go from nan to valid for at least 3 steps\n",
    "    \n",
    "    This should be used with a centred, 5 element window like\n",
    "        x.rolling(time=5, center=True, min_periods=1).reduce(rising_filter)\n",
    "        \n",
    "    Note that applying this to a Dask array will load the entire input array\n",
    "    \"\"\"\n",
    "    # Make sure there are enough points\n",
    "    assert(array.shape[axis] == 5)\n",
    "    # Make sure we're working on the last axis\n",
    "    assert(axis == array.ndim-1 or axis == -1)\n",
    "    \n",
    "    # One entry to the left, should be nan\n",
    "    left = array[..., 1]\n",
    "    # This entry onwards, should not be nan\n",
    "    right = array[..., 2:].sum(axis=axis)\n",
    "\n",
    "    return numpy.logical_and(numpy.isnan(left), numpy.isfinite(right))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In theory this function can be applied to our data using\n",
    "```\n",
    "heatwave_starts = candidates.rolling(time=5, center=True, min_periods=1).reduce(rising_filter)\n",
    "```\n",
    "unfortunately however this doesn't play well with dask, which is the library that handles loading the data from the input files as we need it. If we try then the entire 150 years of daily data gets loaded into memory, and our program will crash.\n",
    "\n",
    "So that we don't need to load the whole array into memory, we need to wrap our filter function using `xarray.apply_ufunc(..., dask='parallelized')`. This tells dask that it can apply the filter on chunks one at a time, it doesn't need the whole array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rising_filter_dask(x, dim):\n",
    "    \"\"\"\n",
    "    Helper function for applying rising_filter() to a dask array without loading the whole thing\n",
    "    \n",
    "    Use like\n",
    "        rising_filter_dask(x.rolling(time=5, center=True, min_periods=1).construct('rolling_dim'),\n",
    "                           dim='rolling_dim')\n",
    "    \"\"\"\n",
    "    return xarray.apply_ufunc(rising_filter, x, input_core_dims=[[dim]],\n",
    "                             kwargs={'axis': -1},\n",
    "                             dask='parallelized',\n",
    "                             output_dtypes=[bool])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dask version of the filter has to be applied slightly differently - this seems to be a bug?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = candidates.chunk({'time':20}).rolling(time=5, center=True, min_periods=1).construct('rolling_dim')\n",
    "heatwave_starts = rising_filter_dask(windows, dim='rolling_dim')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing the whole dataset\n",
    "\n",
    "Finally we have a DataArray with the start time of every heatwave at every gridpoint in the ACCESS 1.3 historical run, that's pretty cheap to calculate - the run time of this notebook should be just a couple minutes.\n",
    "\n",
    "From here we can do some analysis -\n",
    "\n",
    " * Where do heatwaves occur the most? - Create a map of how many heatwaves occured at each grid point between 1990 and 2000\n",
    " \n",
    "<div class=\"accordion\" id=\"accordion\">\n",
    "  <div class=\"card\">\n",
    "    <div class=\"card-header\" id=\"headingOne\">\n",
    "      <h5 class=\"mb-0\">\n",
    "        <button class=\"btn btn-link\" type=\"button\" data-toggle=\"collapse\" data-target=\"#collapse5\">\n",
    "          Answer\n",
    "        </button>\n",
    "      </h5>\n",
    "    </div>\n",
    "  <div>\n",
    "    <div id=\"collapse5\" class=\"collapse\" data-parent=\"#accordion\">\n",
    "      <div class=\"card-body\">\n",
    "<pre><code>\n",
    "%%time\n",
    "# Takes around 30 seconds\n",
    "plt.figure(figsize=(10,5))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "(heatwave_starts.sel(time=slice('1990','2000')).sum('time')/10).plot(ax=ax)\n",
    "ax.coastlines()\n",
    "ax.set_title('Mean yearly heatwave count, 1990-2000 CMIP5 ACCESS 1.3 historical')\n",
    "</code></pre>\n",
    "      </div>\n",
    "    </div>\n",
    "  </div>\n",
    "</div>\n",
    " \n",
    " * How does the frequency change with time? - Create a time-series plot of heatwaves at a single location\n",
    " \n",
    "<div class=\"accordion\" id=\"accordion\">\n",
    "  <div class=\"card\">\n",
    "    <div class=\"card-header\" id=\"headingOne\">\n",
    "      <h5 class=\"mb-0\">\n",
    "        <button class=\"btn btn-link\" type=\"button\" data-toggle=\"collapse\" data-target=\"#collapse6\">\n",
    "          Answer\n",
    "        </button>\n",
    "      </h5>\n",
    "    </div>\n",
    "  <div>\n",
    "    <div id=\"collapse6\" class=\"collapse\" data-parent=\"#accordion\">\n",
    "      <div class=\"card-body\">\n",
    "<pre><code>\n",
    "%%time\n",
    "# Takes about 3 minutes\n",
    "heatwave_starts.sel(lat=-37.8, lon=144.9, method='nearest').groupby('time.year').sum('time').plot()\n",
    "plt.title('Melbourne heatwaves by year, CMIP5 ACCESS 1.3 historical')\n",
    "</code></pre>\n",
    "      </div>\n",
    "    </div>\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the data\n",
    "\n",
    "Before saving the data to disk, here are a few things to think about\n",
    "\n",
    " - Do I need to save the data?\n",
    " - How much data am I creating?\n",
    " - Is the data easy to re-create if I lose it?\n",
    " - Will I know what's in the file in 6 months time?\n",
    " - Can I use compression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "heatwaves = xarray.Dataset({'heatwave_start': heatwave_starts})\n",
    "\n",
    "heatwaves.heatwave_start.attrs['description'] = 'Value is \"1\" if a heatwave started at this time and location, \"0\" otherwise'\n",
    "\n",
    "heatwaves.attrs['title'] = 'Heatwave start times from ACCESS 1.3 historical CMIP5 simulation'\n",
    "heatwaves.attrs['institution'] = 'ARC Centre of Excellence for Climate Extremes'\n",
    "heatwaves.attrs['source'] = 'CMIP5 ACCESS 1.3 historical r1i1p1 daily tasmax'\n",
    "heatwaves.attrs['history'] = \"%s: Calculated using Ipython notebook\"%datetime.now()\n",
    "\n",
    "heatwaves.sel(time='1998').to_netcdf('heatwaves.nc', \n",
    "                    encoding={'heatwave_start': {\n",
    "                        'zlib':True,\n",
    "                        'chunksizes': [200,145,192],\n",
    "                    }})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ncdump -hs heatwaves.nc\n",
    "! ls -sh heatwaves.nc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis3-18.04]",
   "language": "python",
   "name": "conda-env-analysis3-18.04-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
